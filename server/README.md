# Pensar-local server
Implementation of our local LLM inference server. Using Nomic's backend with gguf'ed models.
